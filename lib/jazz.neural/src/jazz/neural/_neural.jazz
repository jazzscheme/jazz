;;;==============
;;;  JazzScheme
;;;==============
;;;
;;;; Neural Networks
;;;
;;;  The contents of this file are subject to the Mozilla Public License Version
;;;  1.1 (the "License"); you may not use this file except in compliance with
;;;  the License. You may obtain a copy of the License at
;;;  http://www.mozilla.org/MPL/
;;;
;;;  Software distributed under the License is distributed on an "AS IS" basis,
;;;  WITHOUT WARRANTY OF ANY KIND, either express or implied. See the License
;;;  for the specific language governing rights and limitations under the
;;;  License.
;;;
;;;  The Original Code is JazzScheme.
;;;
;;;  The Initial Developer of the Original Code is Guillaume Cartier.
;;;  Portions created by the Initial Developer are Copyright (C) 1996-2018
;;;  the Initial Developer. All Rights Reserved.
;;;
;;;  Contributor(s):
;;;
;;;  Alternatively, the contents of this file may be used under the terms of
;;;  the GNU General Public License Version 2 or later (the "GPL"), in which
;;;  case the provisions of the GPL are applicable instead of those above. If
;;;  you wish to allow use of your version of this file only under the terms of
;;;  the GPL, and not to allow others to use your version of this file under the
;;;  terms of the MPL, indicate your decision by deleting the provisions above
;;;  and replace them with the notice and other provisions required by the GPL.
;;;  If you do not delete the provisions above, a recipient may use your version
;;;  of this file under the terms of any one of the MPL or the GPL.
;;;
;;;  See www.jazzscheme.org for details.


(module jazz.neural jazz


(export (jazz.neural.activation)
        (jazz.neural.blas)
        (jazz.neural.data)
        (jazz.neural.io)
        (jazz.neural.layer)
        (jazz.neural.loss)
        (jazz.neural.math)
        (jazz.neural.optimizer)
        (jazz.neural.settings)
        (jazz.neural.syntax)
        (jazz.neural.tensor))

(import (jazz.neural.activation)
        (jazz.neural.blas)
        (jazz.neural.data)
        (jazz.neural.io)
        (jazz.neural.layer)
        (jazz.neural.loss)
        (jazz.neural.math)
        (jazz.neural.optimizer)
        (jazz.neural.settings)
        (jazz.neural.syntax)
        (jazz.neural.tensor)
        (profiler))


(class Model extends Object
  
  
  (slot input         getter generate)
  (slot layers        getter generate)
  (slot optimizer     getter generate)
  (slot loss-function getter generate)
  
  
  (method override (initialize self input-dimension optimizer loss-function)
    (nextmethod self)
    (set! self.input (new Layer input-dimension))
    (set! self.layers '())
    (set! self.optimizer optimizer)
    (set! self.loss-function loss-function))
  
  
  (method override (print self output readably)
    (print-unreadable self output
      (lambda (output)
        (let ((layers (length layers)))
          (format output "{a} layer{a}" layers (format-plural layers))))))
  
  
  (method public (add self layer)
    (setup layer (if (null? layers) input (last layers)) optimizer)
    (set! layers (append! layers (list layer))))
  
  
  (method public (feed-forward self X <Tensor> training?) <Tensor>
    (with& (X)
      (let ((name 'Input))
        (letret& ((layer-output X))
          (for-each (lambda (layer)
                      (when (and neural-print? training?)
                        (tell '-> name)
                        (tell layer-output))
                      (set! name (present layer))
                      (set& layer-output (forward-pass layer layer-output training?)))
                    layers)
          (when (and neural-print? training?)
            (tell '-> name)
            (tell layer-output)
            (tell))
          layer-output))))
  
  
  (method public (propagate-backward self loss-grad <Tensor>)
    (with& (loss-grad)
      (let& ((lg loss-grad))
        (for-each-reversed (lambda (layer)
                             (set& lg (backward-pass layer lg))
                             (when neural-print?
                               (tell '<- 'loss-grad (present layer))
                               (tell lg)))
                           layers))))
  
  
  (method public (train self X <Tensor> y <Tensor>)
    (with& (X y)
      (let& ((y-pred (feed-forward self X #t)))
        (let& ((loss-grad (loss-gradient loss-function y y-pred)))
          (when neural-print?
            (tell '<- 'loss-grad 'Output)
            (tell loss-grad))
          (propagate-backward self loss-grad)))))
  
  
  (method public (fit self X <Tensor> y <Tensor> (epochs: epochs 1) (batch-size: batch-size 64) (feedback: feedback 100))
    (with& (X y)
      (define (do)
        (let ((start (real-time)))
          (let ((batches (ref-object (split-batches X y batch-size))))
            (loop (for epoch from 1 to epochs)
                  (begin
                    (for-each (lambda (batch)
                                (bind (X . y) batch
                                  (train self X y)))
                              batches)
                    (unless neural-print?
                      (when (and feedback (= (modulo epoch feedback) 0))
                        (let ((elapsed (- (real-time) start)))
                          (let ((eps (/ (cast <fl> epoch) elapsed)))
                            (format :terminal "{a} ({r precision: 1} eps){%}" epoch eps)))))))
            (unref-object batches))
          (when neural-print?
            (format :terminal "{%}"))
          (let ((duration (- (real-time) start)))
            (format :terminal "duration: {r precision: 1}{%}" duration))))
      
      (when neural-print?
        (format :terminal "{%}"))
      (if (command-argument "profile")
          (with-profile 'fit
            (lambda ()
              (do)))
        (do))))
  
  
  (method public (test self X <Tensor> y <Tensor>)
    (with& (X y)
      (let& ((y-pred (feed-forward self X #f)))
        (when neural-print?
          (tell)
          (tell '>>)
          (tell y-pred))
        (let ((loss (tensor-mean (loss loss-function y y-pred))))
          (let ((acc (accuracy loss-function y y-pred)))
            (values loss acc))))))
  
  
  (method public (predict self X <Tensor>) <Tensor>
    (with& (X)
      (feed-forward self X #f)))
  
  
  (method public (unref-model self)
    (unref-layer input)
    (for-each unref-layer layers)
    (unref-optimizer optimizer))))
